{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYIEnA4FagtSniL23k4miE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guiOsorio/Learning_JAX/blob/master/Framework_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg6tv5i8ucnK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap, grad, value_and_grad\n",
        "from jax import random\n",
        "import jax\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train basic PyTorch model"
      ],
      "metadata": {
        "id": "2d8inhepA0Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTensorDataset(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "    [data_X, data_y] = dataset\n",
        "    X_tensor, y_tensor = data_X, data_y\n",
        "    tensors = (X_tensor, y_tensor)\n",
        "    assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
        "    self.tensors = tensors\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    x = self.tensors[0][index]\n",
        "\n",
        "    y = self.tensors[1][index]\n",
        "\n",
        "    return x, y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.tensors[0].size(0)"
      ],
      "metadata": {
        "id": "5FnanvBha5TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = torch.tensor([\n",
        "    [2.7810836,2.550537003],\n",
        "    [1.465489372,2.362125076],\n",
        "    [3.396561688,4.400293529],\n",
        "    [1.38807019,1.850220317],\n",
        "    [3.06407232,3.005305973],\n",
        "    [7.627531214,2.759262235],\n",
        "    [5.332441248,2.088626775],\n",
        "    [6.922596716,1.77106367],\n",
        "    [8.675418651,-0.242068655],\n",
        "    [7.673756466,3.508563011]\n",
        "])\n",
        "\n",
        "train_y = torch.tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
        "\n",
        "train_x.shape,train_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGct23YKnCOt",
        "outputId": "2a76b7ab-4574-41ef-c33a-bafaace4c5cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 2]), torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model variables\n",
        "input_size = train_x.size()[1]\n",
        "hidden_size = 1 # number of neurons in hidden layer\n",
        "output_size = 2 # binary = 2 possible solutions\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_size)\n",
        "                      ,nn.Sigmoid()\n",
        "                      ,nn.Linear(hidden_size, output_size))\n",
        "                      # ,nn.Sigmoid()) #why does adding sigmoid mess up the output?\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaHWQi7LplpJ",
        "outputId": "dbe8bd72-24cd-47b7-92cd-40cc2cdeb8bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
              "  (1): Sigmoid()\n",
              "  (2): Linear(in_features=1, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = [train_x, train_y]\n",
        "train_dset = CustomTensorDataset(train)\n",
        "dataloader = DataLoader(train_dset, shuffle=True, num_workers=2)\n",
        "# Define variables for training\n",
        "loss = nn.MSELoss() # mean squared error\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "wzPE-Kpftn8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "start = time.time()\n",
        "\n",
        "# Train PyTorch model\n",
        "for epoch in range(100):\n",
        "  running_loss = 0\n",
        "  for data in dataloader:\n",
        "    x, y = data\n",
        "    optimizer.zero_grad() # reset gradients\n",
        "    loss_val = loss(model(x), y) # calculate loss\n",
        "    loss_val.backward() # calculate gradients\n",
        "    optimizer.step() # update weights\n",
        "    running_loss += loss_val.item()\n",
        "  losses.append(running_loss)\n",
        "end = time.time()\n",
        "\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v8j-xG7vsSV",
        "outputId": "a6fc1000-d0cb-4b43-82c5-900cea7faff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18.41679811477661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "E1wkqBUe4UxW",
        "outputId": "32226bb4-ab62-4ca3-b28f-175bdf27deb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f044b519390>]"
            ]
          },
          "metadata": {},
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test PyTorch model on credit card dataset, keep track of time of training and prediction"
      ],
      "metadata": {
        "id": "9OM2YmugArXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "url = 'https://raw.githubusercontent.com/nsethi31/Kaggle-Data-Credit-Card-Fraud-Detection/master/creditcard.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "idulwBTJrCzN",
        "outputId": "e2f1b7ca-ab17-4cee-fd89-56a2f3232b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d905e47b-a5eb-454d-9efb-e0e7e1058657\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d905e47b-a5eb-454d-9efb-e0e7e1058657')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d905e47b-a5eb-454d-9efb-e0e7e1058657 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d905e47b-a5eb-454d-9efb-e0e7e1058657');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide into features and labels\n",
        "df_x2 = df.iloc[:, 1:4]\n",
        "df_y2 = df['Class'].to_frame()\n",
        "\n",
        "total_points = df_y2.shape[0]\n",
        "split = round(total_points*0.6)\n",
        "\n",
        "# Convert to tensors\n",
        "train_x2 = torch.tensor(df_x2.values, dtype=torch.float32)[:split]\n",
        "train_y2 = torch.tensor(df_y2.values, dtype=torch.float32)[:split]\n",
        "\n",
        "test_x2 = torch.tensor(df_x2.values, dtype=torch.float32)[split:]\n",
        "test_y2 = torch.tensor(df_y2.values, dtype=torch.float32)[split:]\n",
        "\n",
        "train_x2.size(), train_y2.size(), test_x2.size(), test_y2.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhsZdgNHB1y8",
        "outputId": "a3c569f9-ab2b-4669-fded-fc9803b7bcd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([170884, 3]),\n",
              " torch.Size([170884, 1]),\n",
              " torch.Size([113923, 3]),\n",
              " torch.Size([113923, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define same model as the previous time\n",
        "input_size2 = train_x2.size()[1]\n",
        "hidden_size2 = 10 # number of neurons in hidden layer\n",
        "output_size2 = 1\n",
        "\n",
        "model2 = nn.Sequential(nn.Linear(input_size2, hidden_size2)\n",
        "                      ,nn.Sigmoid()\n",
        "                      ,nn.Linear(hidden_size2, output_size2)\n",
        "                      ,nn.Sigmoid()) #why does adding sigmoid mess up the output?\n",
        "\n",
        "model2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD4rr8FxFAux",
        "outputId": "1f380ead-1765-41be-960f-a79de02e38fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=3, out_features=10, bias=True)\n",
              "  (1): Sigmoid()\n",
              "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
              "  (3): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train2 = [train_x2, train_y2]\n",
        "train_dset2 = CustomTensorDataset(train2)\n",
        "dataloader2 = DataLoader(train_dset2, batch_size=100, shuffle=True)\n",
        "\n",
        "# Define variables for training\n",
        "loss2 = nn.MSELoss() # mean squared error\n",
        "optimizer2 = optim.SGD(model2.parameters(), lr=0.2)"
      ],
      "metadata": {
        "id": "rGKnjXwrGCPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses2 = []\n",
        "start2 = time.time()\n",
        "\n",
        "# Train PyTorch model\n",
        "for epoch in range(10):\n",
        "  running_loss = 0\n",
        "  for data in dataloader2:\n",
        "    x, y = data\n",
        "    optimizer2.zero_grad() # reset gradients\n",
        "    loss_val = loss2(model2(x), y) # calculate loss\n",
        "    loss_val.backward() # calculate gradients\n",
        "    optimizer2.step() # update weights\n",
        "    running_loss += loss_val.item()\n",
        "  losses2.append(running_loss)\n",
        "end2 = time.time()\n",
        "\n",
        "print(end2-start2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F26UyIf9G5Bi",
        "outputId": "3072f078-b1f4-45a3-ff52-06ad2798c6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20.641268253326416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "bGJz3xkSG7-9",
        "outputId": "0950534f-7ac6-4137-c51e-e6648e846efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f044b7dd5d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 136
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set\n",
        "correct = 0\n",
        "total = test_y2.size()[0]\n",
        "for features, label in zip(test_x2, test_y2):\n",
        "    pred = 0 if model2(features).item() < 0.5 else 1\n",
        "    l = label.item()\n",
        "    if pred == l:\n",
        "      correct += 1\n",
        "accuracy = correct / total\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNW_Tuz4j1u9",
        "outputId": "8876f291-5838-418b-ef5f-8599b858c1e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9988413226477533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch model times\n",
        "##### With no hardware accelerator:\n",
        "- Model 1 (100 epochs, num_workers=2) -> **8.6883 s**\n",
        "- Model 2 (10 epochs, batch_size=100, num_workers=10) -> \n",
        "\n",
        "##### With GPU hardware accelerator:\n",
        "- Model 1 (100 epochs, num_workers=2) -> **7.9927 s**\n",
        "- Model 2 (10 epochs, batch_size=100, num_workers=10)\n",
        "  - **4.8472 s**\n",
        "  - **accuracy of 99.35%**\n",
        "- Model 2 (10 epochs, num_workers = 10) \n",
        "  - **179.3489 s** \n",
        "  - **accuracy of 99.55%**\n",
        "- Model 2 (10 epochs)\n",
        "  - **37.5481 s**\n",
        "  - **accuracy of 99.6%**\n",
        "\n",
        "Results are expected using the first 10000 data points of the original data with 3 features, with an 80/20 train test split.\n",
        "\n",
        "## Final Model\n",
        "\n",
        "- Model 2 on entire dataset with 60/40 split & batch_size=100\n",
        "  - **17.4195 s**\n",
        "  - **accuracy of 99.88%**\n",
        "\n",
        "Further exploration questions/todos:\n",
        "-  why does sigmoid activation in output layer not work on model 1?\n",
        "- what does num_workers do? (note how training of model was faster without workers)\n",
        "- any particular advantages to using nn.Sequential vs nn.Module?\n",
        "- GPU vs TPU, when is it best to use each\n",
        "- do a classification matrix on final model for evaluation\n",
        "- create JAX neural net for Titanic dataset and submit, note accuracy in test set\n"
      ],
      "metadata": {
        "id": "tKCP-fgrIMiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build same model with JAX on credit card dataset - keep track of time of training and prediction and compare to PyTorch's model"
      ],
      "metadata": {
        "id": "gDeMb2IQA-tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize parameters of the model\n",
        "seed = 0\n",
        "\n",
        "def init_params(layers_size, parent_key):\n",
        "\n",
        "  params = []\n",
        "  # From a parent key, generate different keys for each layer\n",
        "  keys = jax.random.split(parent_key, num=len(layers_size)-1) # understand better what split does/why is it useful\n",
        "\n",
        "  # Set sizes of layers in the model (inputs to layers and outputs to layers)\n",
        "  in_layers = layers_size[:-1]\n",
        "  out_of_layers = layers_size[1:]\n",
        "\n",
        "  for in_layer, out_of_layer, key in zip(in_layers, out_of_layers, keys):\n",
        "    weights_key, bias_key = jax.random.split(key)\n",
        "\n",
        "    # Initialize params to be an array [weights, bias]\n",
        "    #where the weights are n rows (number of neurons, outputs to layer, inputs to next layer) x m columns (number of inputs to layer, outputs from previous layer/features)\n",
        "    #bias are n rows x 1 column (one bias per neuron)\n",
        "    params.append([\n",
        "        0.1*jax.random.normal(weights_key, shape=(out_of_layer, in_layer)) # n x m matrix\n",
        "        ,0.1*jax.random.normal(bias_key, shape=(out_of_layer,)) # vector with n values\n",
        "    ])\n",
        "\n",
        "  return params\n",
        "key3 = jax.random.PRNGKey(seed)\n",
        "params3 = init_params([3,10,1], key3)\n",
        "\n",
        "# Go through each layer of the initialized params and check if the shape is the expected one\n",
        "jax.tree_map(lambda x: x.shape, params3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUB1MviT959t",
        "outputId": "01cf7067-b3c9-41d4-b034-ec45c8b48cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(10, 3), (10,)], [(1, 10), (1,)]]"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to predict using the initialized neural net\n",
        "def predict(params, x):\n",
        "  hiddens = params[:-1] # take all hidden layers of the model (only one in our case)\n",
        "  \n",
        "  # Create a variable that will forward through the network (except the final layer) and store its output, based on an initial input\n",
        "  output_x = x\n",
        "  # Forward pass of x into the hidden layers\n",
        "  for w, b in hiddens:\n",
        "    output_x = jax.nn.sigmoid(jnp.dot(w, output_x) + b)\n",
        "  # at the end of this for loop, we have the inputs to the final layer of the network\n",
        "\n",
        "  # Forward pass output layer \n",
        "  #(done separately because often the final activation is different. if activation is the same, this operation can be implemented in the for loop above)\n",
        "  ws_last, b_last = params[-1]\n",
        "  final_output = jnp.dot(ws_last, output_x) + b_last\n",
        "\n",
        "  return final_output\n",
        "\n",
        "print(predict(params3, train_x2[0].numpy()))\n",
        "\n",
        "batched_predict = vmap(predict, in_axes=(None, 0))\n",
        "\n",
        "print(batched_predict(params3, train_x2[0:2].numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qrPT_nuGyUa",
        "outputId": "871d5948-70ca-4272-b27c-aacbb839228e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06454311]\n",
            "[[0.06454311]\n",
            " [0.06740828]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch):\n",
        "    transposed_data = list(zip(*batch))\n",
        "\n",
        "    labels = np.stack(transposed_data[1])\n",
        "    features = np.stack(transposed_data[0])\n",
        "\n",
        "    return features, labels"
      ],
      "metadata": {
        "id": "qEbg5MIHHsnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "# Create train and test dataloaders\n",
        "train_dl3 = DataLoader(train_dset2, batch_size=batch_size, collate_fn=custom_collate_fn, shuffle=True)\n",
        "\n",
        "test3 = [test_x2, test_y2] # same data as in last model\n",
        "test_dset3 = CustomTensorDataset(test3)\n",
        "test_dl3 = DataLoader(test_dset3, batch_size=batch_size, collate_fn=custom_collate_fn, shuffle=False)\n",
        "\n",
        "# Print shapes of each batch to see if it matches up with the expected shapes based on our batch size\n",
        "for x, y in train_dl3:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  break\n",
        "print('----')\n",
        "for x, y in test_dl3:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioFiq1U9NFWm",
        "outputId": "a55e98a5-cf69-413c-ecfc-af1d7c328fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 3)\n",
            "(100, 1)\n",
            "----\n",
            "(100, 3)\n",
            "(100, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "def loss_fn(params, features, labels):\n",
        "  \n",
        "  preds = batched_predict(params, features)\n",
        "  err = jnp.abs(preds - labels)\n",
        "\n",
        "  return jnp.mean(jnp.square(err)) # MSE\n",
        "\n",
        "for fs, lbls in test_dl3:\n",
        "  print(loss_fn(params3, fs, lbls))\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1rCcjCUMf8H",
        "outputId": "2e8df283-9843-4ca4-a5c1-d6fa7a4748b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0039056754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update function\n",
        "@jit # jit causes the function inputs to change type\n",
        "def update(params, features, labels, lr=0.2):\n",
        "  loss, grads = value_and_grad(loss_fn)(params, features, labels)\n",
        "\n",
        "  return loss, jax.tree_map(lambda p, g: p - lr*g, params, grads)"
      ],
      "metadata": {
        "id": "gl20By9uPXqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy function\n",
        "def accuracy(params, test_dl):\n",
        "  # Return accuracy of model's (params3) predictions based on test dataloader\n",
        "  wrong_count = 0\n",
        "  # i = 0\n",
        "  for x, y in test_dl:\n",
        "    preds = batched_predict(params, x)\n",
        "    wrong_count += jnp.sum(jnp.abs((preds > 0.5) - y))\n",
        "\n",
        "    # i += 1\n",
        "    # if i == 1000:\n",
        "    #   break\n",
        "  return 1 - (wrong_count / len(test_dl))\n",
        "\n",
        "accuracy(params3, test_dl3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BwJm3t8NHUt",
        "outputId": "16508974-0a0b-4cee-a09f-d53dc694eeb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.8842105, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "n_epochs = 10\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  running_loss = 0\n",
        "  for i, (features, labels) in enumerate(train_dl3):\n",
        "\n",
        "    loss, params3 = update(params3, features, labels)\n",
        "    running_loss += loss\n",
        "    # if i % 100 == 0:\n",
        "    #   print(loss)\n",
        "    \n",
        "  print(f'Epoch {epoch}, test acc = {accuracy(params3, test_dl3)}, running loss = {running_loss}')\n",
        "  # print(params3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgNZChUuj3O8",
        "outputId": "f75b6365-ff09-4bef-996d-42d567886b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, test acc = 0.8842105269432068, running loss = 3.428154706954956\n",
            "Epoch 1, test acc = 0.8842105269432068, running loss = 3.332705497741699\n",
            "Epoch 2, test acc = 0.8842105269432068, running loss = 3.279425621032715\n",
            "Epoch 3, test acc = 0.8842105269432068, running loss = 3.1570122241973877\n",
            "Epoch 4, test acc = 0.8842105269432068, running loss = 3.0330605506896973\n",
            "Epoch 5, test acc = 0.8842105269432068, running loss = 2.9695558547973633\n",
            "Epoch 6, test acc = 0.8842105269432068, running loss = 2.9159111976623535\n",
            "Epoch 7, test acc = 0.8842105269432068, running loss = 2.8683111667633057\n",
            "Epoch 8, test acc = 0.8842105269432068, running loss = 2.8470637798309326\n",
            "Epoch 9, test acc = 0.8842105269432068, running loss = 2.8150129318237305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build JAX model for Titanic dataset"
      ],
      "metadata": {
        "id": "_4JcTyYFADQo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lPpzPuuUZBhU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}